---
title: "Publications"
editor: visual
---


::: {.callout-note}
## Links

>- **Google Scholar**: <https://scholar.google.com/citations?user=tlkDP2AAAAAJ>
>- **ORCID**: <https://orcid.org/0000-0002-2011-7535>
>- **ResearchGate:** <https://www.researchgate.net/profile/Yujun-Lian>
:::

&emsp;

## Preprint

#### "*" means authors contributed equally and "#" means corresponding author.

<blockquote style="color: black;  border-width: 8px; border-color: orange">   
  <h4>Strip R-CNN: Large Strip Convolution for Remote Sensing Object Detection</h4>   
  <sub><p style="line-height:15px">Xinbin Yuan, ZhaoHui Zheng, Yuxuan Li, Xialei Liu, Li Liu, Xiang Li, <b>Qibin Hou</b>#, Ming-Ming Cheng#</p> 
  <p style="line-height:15px">Arxiv, 2025</p>   
  <p style="line-height:15px"> <a href="https://arxiv.org/pdf/2501.03775?">[Arxiv]</a> <a href="https://github.com/HVision-NKU/Strip-R-CNN" class="redlink">[Code]</a> <a href="https://zhuanlan.zhihu.com/p/17342348259">[Zhihu]</a> <a href="https://paperswithcode.com/sota/object-detection-in-aerial-images-on-dota-1?p=strip-r-cnn-large-strip-convolution-for">[PaperWithCode]</a></p>   
  </sub>
</blockquote>

<blockquote style="color: black;  border-width: 8px; border-color: orange">   
  <h4>Enhancing Visual Grounding for GUI Agents via Self-Evolutionary Reinforcement Learning</h4>   
  <sub><p style="line-height:15px">Xinbin Yuan, Jian Zhang, Kaixin Li, Zhuoxuan Cai, Lujian Yao, Jie Chen, Enguang Wang, <b>Qibin Hou</b>#, Jinwei Chen, Peng-Tao Jiang, Bo Li#</p> 
  <p style="line-height:15px">Arxiv, 2025</p>   
  <p style="line-height:15px"> <a href="https://arxiv.org/pdf/2505.12370?">[Arxiv]</a> <a href="https://github.com/YXB-NKU/SE-GUI" class="redlink">[Code]</a></p>   
  </sub>
</blockquote>



## Selected Journal Publications ([Google Scholar](https://scholar.google.com/citations?user=fF8OFV8AAAAJ&hl=en))

<blockquote style="color: black;  border-width: 8px; border-color: orange">   
  <h4>Yolo-ms: rethinking multi-scale representation learning for real-time object detection</h4>   
  <sub><p style="line-height:15px"> Yuming Chen, Xinbin Yuan, Ruiqi Wu, Jiabao Wang, <b>Qibin Hou</b>#, Ming-Ming Cheng</p> 
  <p style="line-height:15px">IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 47(6), 4240-4252, 2025</p>   
  <iframe 
src="https://ghbtns.com/github-btn.html?user=FishAndWasabi&repo=YOLO-MS&type=star&count=true&size=small" frameborder="0"
scrolling="0"
width="170"
height="20"
title="GitHub">
</iframe>
  <p style="line-height:15px"> <a href="https://arxiv.org/pdf/2308.05480">[Arxiv]</a> <a href="https://github.com/FishAndWasabi/YOLO-MS" class="redlink">[Code]</a></p>   
  </sub>
</blockquote>

<blockquote style="color: black;  border-width: 8px; border-color: orange">   
  <h4>Conv2former: A simple transformer-style convnet for visual recognition</h4>   
  <sub><p style="line-height:15px"> <b>Qibin Hou</b>, Cheng-Ze Lu, Ming-Ming Cheng#, Jiashi Feng</p> 
  <p style="line-height:15px">IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2024</p>   
  <p style="line-height:15px"> <a href="https://arxiv.org/pdf/2211.11943">[Arxiv]</a> <a href="https://github.com/HVision-NKU/Conv2Former" class="redlink">[Code]</a></p>   
  </sub>
</blockquote>

<blockquote style="color: black;  border-width: 8px; border-color: orange">   
  <h4>Camoformer: Masked separable attention for camouflaged object detection</h4>   
  <sub><p style="line-height:15px">Bowen Yin*, Xuying Zhang*, Deng-Ping Fan, Shaohui Jiao, Ming-Ming Cheng, Luc Van Gool, <b>Qibin Hou</b>#</p> 
  <p style="line-height:15px">IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2024</p>   
  <p style="line-height:15px"> <a href="https://arxiv.org/pdf/2212.06570">[Arxiv]</a> <a href="https://github.com/HVision-NKU/CamoFormer" class="redlink">[Code]</a></p>   
  </sub>
</blockquote>

<blockquote style="color: black;  border-width: 8px; border-color: orange">   
  <h4>Vision permutator: A permutable mlp-like architecture for visual recognition</h4>   
  <sub><p style="line-height:15px"> <b>Qibin Hou</b>, Zihang Jiang, Li Yuan, Ming-Ming Cheng, Shuicheng Yan, Jiashi Feng</p> 
  <p style="line-height:15px">IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2023</p>   
  <p style="line-height:15px"> <a href="https://arxiv.org/pdf/2106.12368.pdf">[Arxiv]</a> <a href="https://github.com/Andrew-Qibin/VisionPermutator" class="redlink">[Code]</a></p>   
  </sub>
</blockquote>

<blockquote style="color: black;  border-width: 8px; border-color: orange">   
  <h4>Deeply Supervised Salient Object Detection with Short Connections</h4>   
  <sub><p style="line-height:15px"> <b>Qibin Hou</b>, Ming-Ming Cheng, Xiaowei Hu, Ali Borji, Zhuowen Tu, Philip Torr</p> 
  <p style="line-height:15px">IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017</p> 
  <p style="line-height:15px">IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2019</p>   
  <p style="line-height:15px"> <a href="https://arxiv.org/pdf/2306.04300.pdf">[Arxiv]</a> <a href="https://github.com/Andrew-Qibin/DSS" class="redlink">[Code]</a></p>   
  </sub>
</blockquote>

## Selected Conference Publications ([Google Scholar](https://scholar.google.com/citations?user=fF8OFV8AAAAJ&hl=en))

<blockquote style="color: black;  border-width: 8px; border-color: orange">   
  <h4>TAR3D: Creating High-Quality 3D Assets via Next-Part Prediction</h4>   
  <sub><p style="line-height:15px">Xuying Zhang*, Yutong Liu*, Yangguang Li, Renrui Zhang, Yufei Liu, Kai Wang, Wanli Ouyang, Zhiwei Xiong, Peng Gao, <b>Qibin Hou</b>#, Ming-Ming Cheng</p> 
  <p style="line-height:15px">IEEE International Conference on Computer Vision (ICCV), 2025</p>   
    <iframe 
src="https://ghbtns.com/github-btn.html?user=HVision-NKU&repo=TAR3D&type=star&count=true&size=small" frameborder="0"
scrolling="0"
width="170"
height="20"
title="GitHub">
</iframe>
  <p style="line-height:15px"> <a href="https://arxiv.org/pdf/2412.16919">[Arxiv]</a> <a href="https://github.com/HVision-NKU/TAR3D?tab=readme-ov-file">[Code]</a></p>   
  </sub>
</blockquote>

<blockquote style="color: black;  border-width: 8px; border-color: orange">   
  <h4>Unbiased Region-Language Alignment for Open-Vocabulary Dense Prediction</h4>   
  <sub><p style="line-height:15px">Yunheng Li, Yuxuan Li, Quansheng Zeng, Wenhai Wang, <b>Qibin Hou</b>#, Ming-Ming Cheng</p> 
  <p style="line-height:15px">IEEE International Conference on Computer Vision (ICCV), 2025</p>    
  <p style="line-height:15px"> <a href="https://arxiv.org/pdf/2412.06244">[Arxiv]</a> <a href="https://github.com/HVision-NKU/DenseVLM" class="redlink">[Code]</a></p>   
  </sub>
</blockquote>

<blockquote style="color: black;  border-width: 8px; border-color: orange">   
  <h4>DFormerv2: Geometry Self-Attention for RGBD Semantic Segmentation</h4>   
  <sub><p style="line-height:15px"> Bo-Wen Yin, Jiao-Long Cao, Ming-Ming Cheng, <b>Qibin Hou</b>#</p> 
  <p style="line-height:15px">IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2025</p>   
    <iframe 
src="https://ghbtns.com/github-btn.html?user=VCIP-RGBD&repo=DFormer&type=star&count=true&size=small" frameborder="0"
scrolling="0"
width="170"
height="20"
title="GitHub">
</iframe>
  <p style="line-height:15px"> <a href="https://arxiv.org/pdf/2504.04701?">[Arxiv]</a> <a href="https://github.com/VCIP-RGBD/DFormer">[Code]</a></p>   
  </sub>
</blockquote>

<blockquote style="color: black;  border-width: 8px; border-color: orange">   
  <h4>StoryDiffusion: Consistent Self-Attention for Long-Range Image and Video Generation</h4>   
  <sub><p style="line-height:15px"> Yupeng Zhou, Daquan Zhou#, Ming-Ming Cheng, Jiashi Feng, <b>Qibin Hou</b># </p>
  <p style="line-height:15px">Neural Information Processing Systems (NeurIPS), 2024</p>   
  <iframe 
src="https://ghbtns.com/github-btn.html?user=HVision-NKU&repo=StoryDiffusion&type=star&count=true&size=small" frameborder="0"
scrolling="0"
width="170"
height="20"
title="GitHub">
</iframe>
  <p style="line-height:15px"> <a href="https://arxiv.org/pdf/2405.01434">[Arxiv]</a> <a href="https://storydiffusion.github.io/" class="redlink">[Project]</a> <a href="https://github.com/HVision-NKU/StoryDiffusion" class="redlink">[Code]</a> </p>   
  </sub>
</blockquote>

<blockquote style="color: black;  border-width: 8px; border-color: orange">   
  <h4>OPUS: Occupancy Prediction Using a Sparse Set</h4>   
  <sub><p style="line-height:15px"> Jiabao Wang*, Zhaojiang Liu*, Qiang Meng, Liujiang Yan, Ke Wang, Jie Yang, Wei Liu, <b>Qibin Hou#</b>, Ming-Ming Cheng</p> 
  <p style="line-height:15px">Neural Information Processing Systems (NeurIPS), 2024</p>   
  <p style="line-height:15px"> <a href="https://arxiv.org/pdf/2409.09350">[Arxiv]</a> <a href="https://github.com/jbwang1997/OPUS">[Code]</a></p>   
  </sub>
</blockquote>

<blockquote style="color: black;  border-width: 8px; border-color: orange">   
  <h4>Dformer: Rethinking rgbd representation learning for semantic segmentation</h4>   
  <sub><p style="line-height:15px"> Bowen Yin, Xuying Zhang, Zhongyu Li, Li Liu, Ming-Ming Cheng, <b>Qibin Hou#</b> </p> 
  <p style="line-height:15px">International Conference on Learning Representations (ICLR), 2024</p>  
   <iframe 
src="https://ghbtns.com/github-btn.html?user=VCIP-RGBD&repo=DFormer&type=star&count=true&size=small" frameborder="0"
scrolling="0"
width="170"
height="20"
title="GitHub">
</iframe>
  <p style="line-height:15px"> <a href="https://arxiv.org/pdf/2309.09668.pdf">[Arxiv]</a> <a href="https://github.com/VCIP-RGBD/DFormer">[Code]</a></p>   
  </sub>
</blockquote>

<blockquote style="color: black;  border-width: 8px; border-color: orange">   
  <h4>SRFormer: Permuted Self-Attention for Single Image Super-Resolution</h4>   
  <sub><p style="line-height:15px"> Yupeng Zhou, Zhen Li, Chun-Le Guo, Song Bai, Ming-Ming Cheng, <b>Qibin Hou#</b> </p> 
  <p style="line-height:15px">IEEE International Conference on Computer Vision (ICCV), 2023</p>   
  <iframe 
src="https://ghbtns.com/github-btn.html?user=HVision-NKU&repo=SRFormer&type=star&count=true&size=small" frameborder="0"
scrolling="0"
width="170"
height="20"
title="GitHub">
</iframe>
  <p style="line-height:15px"> <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_SRFormer_Permuted_Self-Attention_for_Single_Image_Super-Resolution_ICCV_2023_paper.pdf">[Arxiv]</a> <a href="https://github.com/HVision-NKU/SRFormer">[Code]</a></p>   
  </sub>
</blockquote>

<blockquote style="color: black;  border-width: 8px; border-color: orange">   
  <h4>Coordinate attention for efficient mobile network design</h4>   
  <sub><p style="line-height:15px"> <b>Qibin Hou</b>, Daquan Zhou, Jiashi Feng</p> 
  <p style="line-height:15px">IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2021</p>   
  <iframe 
src="https://ghbtns.com/github-btn.html?user=houqb&repo=CoordAttention&type=star&count=true&size=small" frameborder="0"
scrolling="0"
width="170"
height="20"
title="GitHub">
</iframe>
  <p style="line-height:15px"> <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Hou_Coordinate_Attention_for_Efficient_Mobile_Network_Design_CVPR_2021_paper.pdf">[Arxiv]</a> <a href="https://github.com/Andrew-Qibin/
CoordAttention">[Code]</a></p>   
  </sub>
</blockquote>
